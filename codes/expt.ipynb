{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "def process_and_plot(nifti_file1, nifti_file2):\n",
    "\n",
    "    img1 = nib.load(nifti_file1)    #3D Image. this will be processed network map results\n",
    "    data1 = img1.get_fdata()\n",
    "\n",
    "    img2 = nib.load(nifti_file2)    #4D Image. this will be original function files\n",
    "    data2 = img2.get_fdata()\n",
    "\n",
    "    # sample_target_image = data2[:,:,:,0]\n",
    "\n",
    "    data1_resampled = resample_to_img(img1, img2)    #resampled image\n",
    "\n",
    "    print(data1_resampled.get_fdata().shape)\n",
    "\n",
    "    mask = (data1_resampled.get_fdata() > 0.1).astype(int)\n",
    "\n",
    "    result = data2 * mask[:, :, :, np.newaxis]\n",
    "    avg_result = np.mean(result, axis=(0, 1, 2))\n",
    "\n",
    "\n",
    "    plt.plot(avg_result)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.title('Average Value Over Time')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "nifti_file1 = '/home/sachin/Music/neurabeats/fmri_files/Viewer(Non-Dicom)/network_maps/language.nii.gz'   #3D file\n",
    "nifti_file2 = '/home/sachin/Music/neurabeats/fmri_files/_rsfMRI_BAI_Connectomics_20241209101429_601.nii.gz'  #4D File\n",
    "\n",
    "process_and_plot(nifti_file1, nifti_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is place holder code from Gemini\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def image_to_audio(image_signal, output_file='output.wav', sample_rate=44100, duration=5):\n",
    "    \"\"\"\n",
    "    Converts a mean image signal to a simple audio signal.\n",
    "\n",
    "    Args:\n",
    "        image_signal: The mean image signal as a 2D NumPy array.\n",
    "        output_file: The desired output filename.\n",
    "        sample_rate: The desired sample rate of the audio.\n",
    "        duration: The desired duration of the audio in seconds.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize the image signal\n",
    "    normalized_signal = (image_signal - np.min(image_signal)) / (np.max(image_signal) - np.min(image_signal))\n",
    "\n",
    "    # Reshape the signal into a 1D array\n",
    "    signal_1d = normalized_signal.flatten()\n",
    "\n",
    "    # Create an audio array with the desired sample rate and duration\n",
    "    audio_array = np.interp(np.arange(0, duration * sample_rate), np.linspace(0, len(signal_1d) - 1, duration * sample_rate), signal_1d))\n",
    "\n",
    "    # Scale the audio array to the range of 16-bit signed integers\n",
    "    audio_array = (audio_array * 32767).astype(np.int16)\n",
    "\n",
    "    # Write the audio array to a WAV file\n",
    "    write(output_file, sample_rate, audio_array)\n",
    "\n",
    "    # Create an AudioSegment object for further processing (optional)\n",
    "    audio_segment = AudioSegment.from_wav(output_file)\n",
    "\n",
    "    # Apply audio effects or modifications to the audio_segment (optional)\n",
    "    # ...\n",
    "\n",
    "    # Save the modified audio segment to a new file (optional)\n",
    "    # audio_segment.export(output_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Step 1: Create or load your signal\n",
    "duration = 5  # seconds\n",
    "sampling_rate = 44100  # Hz\n",
    "t = np.linspace(0, duration, int(sampling_rate * duration), endpoint=False)\n",
    "frequency = 440.0  # A4 note, 440 Hz\n",
    "signal = 0.5 * np.sin(2 * np.pi * frequency * t)  # Sine wave at 440 Hz\n",
    "\n",
    "# Step 2: Save the signal to an audio file\n",
    "output_file = \"output_audio.wav\"\n",
    "sf.write(output_file, signal, sampling_rate)\n",
    "\n",
    "print(f\"Audio file saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Step 1: Define your signal\n",
    "num_points = 160\n",
    "sampling_interval = 2.8  # seconds\n",
    "sampling_rate = 1 / sampling_interval  # Hz\n",
    "\n",
    "# Create a time array for 160 points\n",
    "t = np.linspace(0, num_points * sampling_interval, num_points, endpoint=False)\n",
    "\n",
    "# Example signal: Sine wave at 0.1 Hz (very low frequency, almost inaudible)\n",
    "frequency = 0.1  # Hz\n",
    "signal = 0.5 * np.sin(2 * np.pi * frequency * t)  # Sine wave\n",
    "\n",
    "# Step 2: Save the signal to an audio file\n",
    "output_file = \"output_audio.wav\"\n",
    "sf.write(output_file, signal, int(sampling_rate))  #we will get an Internal error : SF_INFO struct incomplete due to low sampling rate\n",
    "\n",
    "print(f\"Audio file saved as {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Step 1: Define your signal\n",
    "num_points = 160\n",
    "sampling_interval = 2.8  # seconds\n",
    "original_sampling_rate = 1 / sampling_interval  # Hz\n",
    "\n",
    "# Create a time array for 160 points\n",
    "t = np.linspace(0, num_points * sampling_interval, num_points, endpoint=False)\n",
    "\n",
    "# Example signal: Sine wave at 0.1 Hz (very low frequency)\n",
    "frequency = 0.1  # Hz\n",
    "signal = 0.5 * np.sin(2 * np.pi * frequency * t)  # Sine wave\n",
    "\n",
    "# Step 2: Resample the signal to a higher sampling rate (e.g., 44100 Hz)\n",
    "target_sampling_rate = 44100  # Hz\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Calculate the number of samples for the target sampling rate\n",
    "num_resampled_points = int(len(signal) * (target_sampling_rate / original_sampling_rate))\n",
    "resampled_signal = resample(signal, num_resampled_points)\n",
    "\n",
    "# Step 3: Save the resampled signal to an audio file\n",
    "output_file = \"output_audio_resampled.wav\"\n",
    "sf.write(output_file, resampled_signal, target_sampling_rate)\n",
    "\n",
    "print(f\"Audio file saved as {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
